{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_with_seq = pd.read_csv(\"./data/negative_examples.csv\")\n",
    "positive_with_seq = pd.read_csv(\"./data/positive_examples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 15218,  15223,  15224, ..., 153676, 153677, 153678]),)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = positive_with_seq[\"seq_new\"].apply(lambda x: True if \"N\" in x else False)\n",
    "np.where(n == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [1, 0, 0, 0, 0],\n 'C': [0, 1, 0, 0, 0],\n 'G': [0, 0, 1, 0, 0],\n 'T': [0, 0, 0, 1, 0],\n 'N': [0, 0, 0, 0, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases = dict(zip(\"ACGTN\", [[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]]))\n",
    "bases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_positive = []\n",
    "def encode(row):\n",
    "    result = []\n",
    "    for base in row:\n",
    "        result.append(bases[base])\n",
    "        \n",
    "    X_positive.append(result)\n",
    "positive_with_seq[\"seq_new\"].apply(encode)\n",
    "X_positive[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_negative = []\n",
    "def encode_neg(row):\n",
    "    result = []\n",
    "    for base in row:\n",
    "        result.append(bases[base])\n",
    "        \n",
    "    X_negative.append(result)\n",
    "negative_with_seq[\"seq_new\"].apply(encode_neg)\n",
    "X_negative[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166348, 400, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((X_positive, X_negative), axis=0)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [1, 0, 0, 0, 0], [0, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [bases[\"A\"],bases[\"C\"]]\n",
    "e = [bases[\"A\"],bases[\"C\"], bases[\"A\"], bases[\"C\"]]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_con = np.concatenate((d, e), axis=0)\n",
    "test_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pos = [[1]] * len(X_positive)\n",
    "Y_neg = [[0]] * len(X_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((Y_pos, Y_neg), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111453, 400, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18270bcbe0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.figure(figsize=(15, 5))\n",
    "plt.pyplot.matshow(X_train[999,:50,:].transpose(), vmin=0, vmax=1, cmap=plt.pyplot.cm.coolwarm, fignum=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18267f66d8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.figure(figsize=(15, 5))\n",
    "plt.pyplot.matshow(X_train[998,:50,:].transpose(), vmin=0, vmax=1, cmap=plt.pyplot.cm.coolwarm, fignum=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54895, 400, 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.reshape([111453, 2000])\n",
    "train_labels = y_train\n",
    "eval_data = X_test.reshape([54895, 2000])\n",
    "eval_labels = y_test\n",
    "\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "number_of_outputs = 1\n",
    "number_of_inputs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111453, 2000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Training Cost: 0.33564919233322144  Testing Cost: 0.33652159571647644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - Training Cost: 0.09372221678495407  Testing Cost: 0.09169992804527283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 - Training Cost: 0.09237436950206757  Testing Cost: 0.08941369503736496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 - Training Cost: 0.07734972983598709  Testing Cost: 0.07512230426073074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 - Training Cost: 0.072813019156456  Testing Cost: 0.07045739144086838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 - Training Cost: 0.07167725265026093  Testing Cost: 0.06927438825368881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 - Training Cost: 0.0713334009051323  Testing Cost: 0.06926854699850082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 - Training Cost: 0.06992018222808838  Testing Cost: 0.06757499277591705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 - Training Cost: 0.0689697116613388  Testing Cost: 0.06673672795295715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 - Training Cost: 0.06906340271234512  Testing Cost: 0.06699341535568237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - Training Cost: 0.06848178058862686  Testing Cost: 0.06632641702890396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 - Training Cost: 0.0684622973203659  Testing Cost: 0.06626429408788681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 - Training Cost: 0.06819421797990799  Testing Cost: 0.06605736166238785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 - Training Cost: 0.0680912584066391  Testing Cost: 0.06602340191602707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 - Training Cost: 0.06799395382404327  Testing Cost: 0.06595398485660553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 - Training Cost: 0.067872554063797  Testing Cost: 0.06583758443593979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 - Training Cost: 0.06778432428836823  Testing Cost: 0.06575614213943481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 - Training Cost: 0.06770839542150497  Testing Cost: 0.06569990515708923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 - Training Cost: 0.06763370335102081  Testing Cost: 0.06565184146165848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95 - Training Cost: 0.06756138801574707  Testing Cost: 0.06561208516359329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training cost: 0.06750517338514328\nFinal Testing cost: 0.06558830291032791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs), name=\"X\")\n",
    "\n",
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "# Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output, weights) + biases\n",
    "\n",
    "# Section Two: Define the cost function of the neural network that will be optimized during training\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1), name=\"Y\")\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
    "\n",
    "# Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "RUN_NAME = \"run 1 with 50 nodes\"\n",
    "# Initialize a session so that we can run TensorFlow operations\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    training_writer = tf.summary.FileWriter(\"./logs/{}/training\".format(RUN_NAME), session.graph)\n",
    "    testing_writer = tf.summary.FileWriter(\"./logs/{}/testing\".format(RUN_NAME), session.graph)\n",
    "\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: train_data, Y: train_labels})\n",
    "\n",
    "        # Every few training steps, log our progress\n",
    "        if epoch % 5 == 0:\n",
    "            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "            training_cost, training_summary = session.run([cost, summary], feed_dict={X: train_data, Y:train_labels})\n",
    "            testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: eval_data, Y:eval_labels})\n",
    "    \n",
    "            # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "            training_writer.add_summary(training_summary, epoch)\n",
    "            testing_writer.add_summary(testing_summary, epoch)\n",
    "    \n",
    "            # Print the current training status to the screen\n",
    "            print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "\n",
    "    # Training is now complete!\n",
    "\n",
    "    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "    final_training_cost = session.run(cost, feed_dict={X: train_data, Y: train_labels})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: eval_data, Y: eval_labels})\n",
    "\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
