{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_with_seq = pd.read_csv(\"./data/negative_examples.csv\")\n",
    "positive_with_seq = pd.read_csv(\"./data/positive_examples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 15218,  15223,  15224, ..., 153676, 153677, 153678]),)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = positive_with_seq[\"seq_new\"].apply(lambda x: True if \"N\" in x else False)\n",
    "np.where(n == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': [1, 0, 0, 0, 0],\n 'C': [0, 1, 0, 0, 0],\n 'G': [0, 0, 1, 0, 0],\n 'T': [0, 0, 0, 1, 0],\n 'N': [0, 0, 0, 0, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bases = dict(zip(\"ACGTN\", [[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]]))\n",
    "bases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_positive = []\n",
    "def encode(row):\n",
    "    result = []\n",
    "    for base in row:\n",
    "        result.append(bases[base])\n",
    "        \n",
    "    X_positive.append(result)\n",
    "positive_with_seq[\"seq_new\"].apply(encode)\n",
    "X_positive[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_negative = []\n",
    "def encode_neg(row):\n",
    "    result = []\n",
    "    for base in row:\n",
    "        result.append(bases[base])\n",
    "        \n",
    "    X_negative.append(result)\n",
    "negative_with_seq[\"seq_new\"].apply(encode_neg)\n",
    "X_negative[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166348, 400, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate((X_positive, X_negative), axis=0)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [bases[\"A\"],bases[\"C\"]]\n",
    "e = [bases[\"A\"],bases[\"C\"], bases[\"A\"], bases[\"C\"]]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0],\n       [1, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_con = np.concatenate((d, e), axis=0)\n",
    "test_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pos = [[1]] * len(X_positive)\n",
    "Y_neg = [[0]] * len(X_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((Y_pos, Y_neg), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111453, 400, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182086d748>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.figure(figsize=(15, 5))\n",
    "plt.pyplot.matshow(X_train[999,:50,:].transpose(), vmin=0, vmax=50, cmap=plt.pyplot.cm.coolwarm, fignum=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181bf11f28>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.figure(figsize=(15, 5))\n",
    "plt.pyplot.matshow(X_train[998,:50,:].transpose(), vmin=0, vmax=50, cmap=plt.pyplot.cm.coolwarm, fignum=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train\n",
    "train_labels = y_train\n",
    "eval_data = y_train\n",
    "eval_labels = y_test\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "number_of_outputs = 1\n",
    "number_of_inputs = train_data.shape[1]\n",
    "number_of_inputs\n",
    "tf.reset_default_graph()\n",
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 400, 5), name=\"X\")\n",
    "    \n",
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(\"weights1\", shape=[400, 5, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.einsum('nij,ijk->nik', X, weights) + biases)\n",
    "\n",
    "\n",
    "# Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(\"weights2\", shape=[400, layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.einsum('nij,ijk->nik', layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(\"weights3\", shape=[400, layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.einsum('nij,ijk->nik', layer_2_output, weights) + biases)\n",
    "\n",
    "with tf.variable_scope('layer_drop'):    \n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=layer_3_output, rate=0.4)\n",
    "\n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(\"weights4\", shape=[400, layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.einsum('nij,ijk->nik', dropout, weights) + biases\n",
    "    \n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1), name=\"Y\")\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))   \n",
    "    \n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "RUN_NAME = \"run 1 with 5 nodes\"\n",
    "# Initialize a session so that we can run TensorFlow operations\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    training_writer = tf.summary.FileWriter(\"./logs/{}/training\".format(RUN_NAME), session.graph)\n",
    "    testing_writer = tf.summary.FileWriter(\"./logs/{}/testing\".format(RUN_NAME), session.graph)\n",
    "\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: train_data, Y: train_labels})\n",
    "\n",
    "        # Every few training steps, log our progress\n",
    "        # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "        training_cost, training_summary = session.run([cost, summary], feed_dict={X: train_data, Y:train_labels})\n",
    "        testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: eval_data, Y:eval_labels})\n",
    "\n",
    "        # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "        training_writer.add_summary(training_summary, epoch)\n",
    "        testing_writer.add_summary(testing_summary, epoch)\n",
    "\n",
    "        # Print the current training status to the screen\n",
    "        print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "\n",
    "    # Training is now complete!\n",
    "\n",
    "    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "    final_training_cost = session.run(cost, feed_dict={X: train_data, Y: train_labels})\n",
    "    final_testing_cost = session.run(cost, feed_dict={X: eval_data, Y: eval_labels})\n",
    "\n",
    "    print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "    print(\"Final Testing cost: {}\".format(final_testing_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_3_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(400), Dimension(400), Dimension(1)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111453, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_7 to have 4 dimensions, but got array with shape (20, 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-49ef0b6c7f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_7 to have 4 dimensions, but got array with shape (20, 1)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 400, 5\n",
    "\n",
    "# the data, split between train and test sets\n",
    "x_train = X_train[:20].reshape(20,400,5,1)\n",
    "y_train = y_train[:20]\n",
    "x_test = X_test[:20].reshape(20,400,5,1)\n",
    "y_test = y_test[:20]\n",
    "\n",
    "input_shape = (400, 5, 1)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]],\n\n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        ..., \n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]],\n\n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        ..., \n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        ..., \n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]]],\n\n\n       ..., \n       [[[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]],\n\n        ..., \n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]]],\n\n\n       [[[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        ..., \n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]]],\n\n\n       [[[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[1],\n         [0],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]],\n\n        ..., \n        [[0],\n         [1],\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [1],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         [1],\n         [0]]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
